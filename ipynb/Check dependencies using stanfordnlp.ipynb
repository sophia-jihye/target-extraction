{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk import Tree\n",
    "\n",
    "def to_nltk_tree(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
    "    else:\n",
    "        return node.orth_\n",
    "\n",
    "nlp_spacy = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         is                  \n",
      "    _____|_________           \n",
      "   |     |      quality      \n",
      "   |     |    _____|______    \n",
      "amazing  .  The         photo\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 'The photo quality is amazing.'\n",
    "doc = nlp_spacy(sample)\n",
    "[to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        continued                                                                   \n",
      "  __________________________________________|_________________________________                                       \n",
      " |   |   |      |          |                                              moderated                                 \n",
      " |   |   |      |          |                 _________________________________|_____________________________         \n",
      " |   |   |      |          |                |      |             growth                  |                  |       \n",
      " |   |   |      |          |                |      |               |                     |                  |        \n",
      " |   |   |      |          |                |      |               of                   from                |       \n",
      " |   |   |      |          |                |      |               |                     |                  |        \n",
      " |   |   |   spending     grow              |      |           investment               pace               year     \n",
      " |   |   |      |       ___|______          |      |      _________|__________        ___|_____        _____|____    \n",
      "has  ,   .  Household  to      strongly   while   has business              fixed   its      rapid earlier      last\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 'Household spending has continued to grow strongly, while growth of business fixed investment has moderated from its rapid pace earlier last year.'\n",
    "doc = nlp_spacy(sample)\n",
    "[to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The DET DT det 2\n",
      "1 photo NOUN NN compound 2\n",
      "2 quality NOUN NN nsubj 3\n",
      "3 is VERB VBZ ROOT 3\n",
      "4 amazing ADJ JJ acomp 3\n",
      "5 . PUNCT . punct 3\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.i, token.text, token.pos_, token.tag_, token.dep_, token.head.i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: gpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "nlp = stanfordnlp.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tThe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t3\tdet\t_\t_\n",
      "2\tphoto\tphoto\tNOUN\tNN\tNumber=Sing\t3\tcompound\t_\t_\n",
      "3\tquality\tquality\tNOUN\tNN\tNumber=Sing\t5\tnsubj\t_\t_\n",
      "4\tis\tbe\tAUX\tVBZ\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t5\tcop\t_\t_\n",
      "5\tamazing\tamazing\tADJ\tJJ\tDegree=Pos\t0\troot\t_\t_\n",
      "6\t.\t.\tPUNCT\t.\t_\t5\tpunct\t_\t_\n",
      "\n",
      "\n",
      "1\tI\tI\tPRON\tPRP\tCase=Nom|Number=Sing|Person=1|PronType=Prs\t4\tnsubj\t_\t_\n",
      "2\tam\tbe\tAUX\tVBP\tMood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin\t4\tcop\t_\t_\n",
      "3\tnot\tnot\tPART\tRB\t_\t4\tadvmod\t_\t_\n",
      "4\tpleased\tpleased\tADJ\tJJ\tDegree=Pos\t0\troot\t_\t_\n",
      "5\twith\twith\tADP\tIN\t_\t8\tcase\t_\t_\n",
      "6\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t8\tdet\t_\t_\n",
      "7\tpicture\tpicture\tNOUN\tNN\tNumber=Sing\t8\tcompound\t_\t_\n",
      "8\tquality\tquality\tNOUN\tNN\tNumber=Sing\t4\tobl\t_\t_\n",
      "9\t.\t.\tPUNCT\t.\t_\t4\tpunct\t_\t_\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = ['The photo quality is amazing.', 'I am not pleased with the picture quality.']\n",
    "for sample in samples:\n",
    "    doc = nlp(sample)\n",
    "    print(doc.conll_file.conll_as_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there there EX expl 2\n",
      "are be VBP root 0\n",
      "a a DT det 5\n",
      "couple couple NN compound 5\n",
      "things thing NNS nsubj 2\n",
      "i i PRP nsubj 9\n",
      "did do VBD aux 9\n",
      "nt not RB advmod 9\n",
      "like like VB acl:relcl 5\n",
      "though though RB advmod 9\n",
      "but but CC cc 12\n",
      "nothing nothing NN conj 2\n",
      "serious serious JJ amod 12\n",
      ": : : punct 2\n",
      "a a DT det 2\n",
      "little little JJ obl:npmod 3\n",
      "larger larger JJR advmod 13\n",
      "than than IN case 6\n",
      "other other JJ amod 6\n",
      "mp3s mp3 NNS obl 3\n",
      "but but CC cc 9\n",
      "still still RB advmod 9\n",
      "light light JJ conj 6\n",
      ", , , punct 13\n",
      "the the DT det 12\n",
      "software software NN nsubj 13\n",
      "takes take VBZ root 0\n",
      "some some DT det 15\n",
      "time time NN obj 13\n",
      "to to TO mark 18\n",
      "get get VB aux:pass 18\n",
      "used use VBN acl 15\n",
      "to to IN obl 18\n",
      "( ( -LRB- punct 25\n",
      "maybe maybe RB advmod 25\n",
      "10 10 CD nummod 25\n",
      "- - SYM case 24\n",
      "15 15 CD nmod 22\n",
      "mins min NNS obl 18\n",
      ") ) -RRB- punct 25\n",
      ", , , punct 34\n",
      "and and CC cc 34\n",
      "this this DT det 30\n",
      "thing thing NN nsubj:pass 34\n",
      "would would MD aux 34\n",
      "definitely definitely RB advmod 34\n",
      "be be VB aux:pass 34\n",
      "destroyed destroy VBN conj 13\n",
      "with with IN case 37\n",
      "one one CD nummod 37\n",
      "fall fall NN obl 34\n",
      ". . . punct 13\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(doc.sentences)):\n",
    "    parsed_doc = doc.sentences[j].dependencies\n",
    "    for i in range(len(parsed_doc)):\n",
    "        print(parsed_doc[i][2].text, end=' ')\n",
    "        print(parsed_doc[i][2].lemma, end=' ')\n",
    "        print(parsed_doc[i][2].xpos, end=' ')\n",
    "        print(parsed_doc[i][2].dependency_relation, end=' ')\n",
    "        print(parsed_doc[i][2].governor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-cd6bf04a2ed7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"transfer through windows explorer - windows recognizes the jukebox as an additional hard disk , so it allows you to simply drag and drop files from windows explorer to a folder for the nomad .\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconll_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconll_as_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparsed_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.6/site-packages/stanfordnlp/pipeline/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.6/site-packages/stanfordnlp/pipeline/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.6/site-packages/stanfordnlp/pipeline/lemma_processor.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0medits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2seq_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beam_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mpreds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.6/site-packages/stanfordnlp/models/lemma/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, batch, beam_size)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medit_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mpred_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'char'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# unmap to tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mpred_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprune_decoded_seqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.6/site-packages/stanfordnlp/models/common/seq2seq_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, src, src_mask, pos, beam_size)\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0mdone\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;31m# update beam state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_origin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.6/site-packages/stanfordnlp/models/common/seq2seq_model.py\u001b[0m in \u001b[0;36mupdate_state\u001b[0;34m(states, idx, positions, beam_size)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0mbr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbr\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# (3) main loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "sample = \"transfer through windows explorer - windows recognizes the jukebox as an additional hard disk , so it allows you to simply drag and drop files from windows explorer to a folder for the nomad .\"\n",
    "doc = nlp(sample)\n",
    "print(doc.conll_file.conll_as_string())\n",
    "parsed_doc = doc.sentences[0].dependencies\n",
    "for i in range(len(parsed_doc)):\n",
    "    print(parsed_doc[i][2].text, end=' ')\n",
    "    print(parsed_doc[i][2].lemma, end=' ')\n",
    "    print(parsed_doc[i][2].xpos, end=' ')\n",
    "    print(parsed_doc[i][2].dependency_relation, end=' ')\n",
    "    print(parsed_doc[i][2].governor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: gpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/dmlab/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "1\tThe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t2\tdet\t_\t_\n",
      "2\tphone\tphone\tNOUN\tNN\tNumber=Sing\t3\tnsubj\t_\t_\n",
      "3\thas\thave\tVERB\tVBZ\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t0\troot\t_\t_\n",
      "4\ta\ta\tDET\tDT\tDefinite=Ind|PronType=Art\t6\tdet\t_\t_\n",
      "5\tgood\tgood\tADJ\tJJ\tDegree=Pos\t6\tamod\t_\t_\n",
      "6\tscreen\tscreen\tNOUN\tNN\tNumber=Sing\t3\tobj\t_\t_\n",
      "7\t.\t.\tPUNCT\t.\t_\t3\tpunct\t_\t_\n",
      "\n",
      "\n",
      "1\tI\tI\tPRON\tPRP\tCase=Nom|Number=Sing|Person=1|PronType=Prs\t4\tnsubj\t_\t_\n",
      "2\tam\tbe\tAUX\tVBP\tMood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin\t4\tcop\t_\t_\n",
      "3\tnot\tnot\tPART\tRB\t_\t4\tadvmod\t_\t_\n",
      "4\tpleased\tpleased\tADJ\tJJ\tDegree=Pos\t0\troot\t_\t_\n",
      "5\twith\twith\tADP\tIN\t_\t8\tcase\t_\t_\n",
      "6\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t8\tdet\t_\t_\n",
      "7\tpicture\tpicture\tNOUN\tNN\tNumber=Sing\t8\tcompound\t_\t_\n",
      "8\tquality\tquality\tNOUN\tNN\tNumber=Sing\t4\tobl\t_\t_\n",
      "9\t.\t.\tPUNCT\t.\t_\t4\tpunct\t_\t_\n",
      "\n",
      "\n",
      "1\tThe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t3\tdet\t_\t_\n",
      "2\tphoto\tphoto\tNOUN\tNN\tNumber=Sing\t3\tcompound\t_\t_\n",
      "3\tquality\tquality\tNOUN\tNN\tNumber=Sing\t5\tnsubj\t_\t_\n",
      "4\tis\tbe\tAUX\tVBZ\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t5\tcop\t_\t_\n",
      "5\tamazing\tamazing\tADJ\tJJ\tDegree=Pos\t0\troot\t_\t_\n",
      "6\t.\t.\tPUNCT\t.\t_\t5\tpunct\t_\t_\n",
      "\n",
      "\n",
      "1\tThe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t2\tdet\t_\t_\n",
      "2\tsoftware\tsoftware\tNOUN\tNN\tNumber=Sing\t8\tnsubj\t_\t_\n",
      "3\tof\tof\tADP\tIN\t_\t5\tcase\t_\t_\n",
      "4\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t5\tdet\t_\t_\n",
      "5\tplayer\tplayer\tNOUN\tNN\tNumber=Sing\t2\tnmod\t_\t_\n",
      "6\tis\tbe\tAUX\tVBZ\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t8\tcop\t_\t_\n",
      "7\tnot\tnot\tPART\tRB\t_\t8\tadvmod\t_\t_\n",
      "8\teasy\teasy\tADJ\tJJ\tDegree=Pos\t0\troot\t_\t_\n",
      "9\t-\t-\tPUNCT\tHYPH\t_\t8\tpunct\t_\t_\n",
      "10\tto\tto\tADP\tIN\t_\t12\tcase\t_\t_\n",
      "11\t-\t-\tPUNCT\tHYPH\t_\t12\tpunct\t_\t_\n",
      "12\tuse\tuse\tVERB\tVB\tVerbForm=Inf\t8\tconj\t_\t_\n",
      "13\t.\t.\tPUNCT\t.\t_\t8\tpunct\t_\t_\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "nlp = stanfordnlp.Pipeline()\n",
    "\n",
    "samples = ['The phone has a good screen.', 'I am not pleased with the picture quality.', 'The photo quality is amazing.', 'The software of the player is not easy-to-use.']\n",
    "for sample in samples:\n",
    "    doc = nlp(sample)\n",
    "    print(doc.conll_file.conll_as_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tThe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t2\tdet\t_\t_\n",
      "2\tsoftware\tsoftware\tNOUN\tNN\tNumber=Sing\t8\tnsubj\t_\t_\n",
      "3\tof\tof\tADP\tIN\t_\t5\tcase\t_\t_\n",
      "4\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t5\tdet\t_\t_\n",
      "5\tplayer\tplayer\tNOUN\tNN\tNumber=Sing\t2\tnmod\t_\t_\n",
      "6\tis\tbe\tAUX\tVBZ\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t8\tcop\t_\t_\n",
      "7\tnot\tnot\tPART\tRB\t_\t8\tadvmod\t_\t_\n",
      "8\teasy\teasy\tADJ\tJJ\tDegree=Pos\t0\troot\t_\t_\n",
      "9\t-\t-\tPUNCT\tHYPH\t_\t8\tpunct\t_\t_\n",
      "10\tto\tto\tADP\tIN\t_\t12\tcase\t_\t_\n",
      "11\t-\t-\tPUNCT\tHYPH\t_\t12\tpunct\t_\t_\n",
      "12\tuse\tuse\tVERB\tVB\tVerbForm=Inf\t8\tconj\t_\t_\n",
      "13\t.\t.\tPUNCT\t.\t_\t8\tpunct\t_\t_\n",
      "\n",
      "\n",
      "1\tThis\tthis\tPRON\tDT\tNumber=Sing|PronType=Dem\t5\tnsubj\t_\t_\n",
      "2\tis\tbe\tAUX\tVBZ\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t5\tcop\t_\t_\n",
      "3\tall\tall\tADV\tRB\t_\t5\tadvmod\t_\t_\n",
      "4\t-\t-\tPUNCT\tHYPH\t_\t5\tpunct\t_\t_\n",
      "5\taround\taround\tADV\tRB\t_\t0\troot\t_\t_\n",
      "6\t.\t.\tPUNCT\t.\t_\t5\tpunct\t_\t_\n",
      "\n",
      "\n",
      "1\tThis\tthis\tPRON\tDT\tNumber=Sing|PronType=Dem\t5\tnsubj\t_\t_\n",
      "2\tis\tbe\tAUX\tVBZ\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t5\tcop\t_\t_\n",
      "3\tbrand\tbrand\tNOUN\tNN\tNumber=Sing\t5\tobl:npmod\t_\t_\n",
      "4\t-\t-\tPUNCT\tHYPH\t_\t5\tpunct\t_\t_\n",
      "5\tnew\tnew\tADJ\tJJ\tDegree=Pos\t0\troot\t_\t_\n",
      "6\t.\t.\tPUNCT\t.\t_\t5\tpunct\t_\t_\n",
      "\n",
      "\n",
      "1\tThis\tthis\tPRON\tDT\tNumber=Sing|PronType=Dem\t3\tnsubj\t_\t_\n",
      "2\tis\tbe\tAUX\tVBZ\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t3\tcop\t_\t_\n",
      "3\teye-catching\teye-catch\tADJ\tJJ\tDegree=Pos\t0\troot\t_\t_\n",
      "4\t.\t.\tPUNCT\t.\t_\t3\tpunct\t_\t_\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:573: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:573: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:573: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:573: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "samples = ['The software of the player is not easy-to-use.', 'This is all-around.', 'This is brand-new.', 'This is eye-catching.']\n",
    "for sample in samples:\n",
    "    doc = nlp(sample)\n",
    "    print(doc.conll_file.conll_as_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtext",
   "language": "python",
   "name": "torchtext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
